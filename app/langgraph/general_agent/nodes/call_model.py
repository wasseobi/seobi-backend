"""LLM í˜¸ì¶œ ë° ì‘ë‹µ ìƒì„± ëª¨ë“ˆ (MCP + ì§ì ‘ êµ¬í˜„ ë„êµ¬ í†µí•©)."""
import json
import logging
import os
from typing import Dict, List, Any, Union
from langchain_core.messages import AIMessage, ToolMessage, BaseMessage, HumanMessage, SystemMessage
from datetime import datetime

from app.utils.openai_client import init_langchain_llm
from app.utils.message.converter import convert_to_openai_messages
from app.utils.message.formatter import format_message_content, format_message_list
from ...tools import agent_tools
from ..agent_state import AgentState
from ....utils.prompt.agent_prompt import prompt

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ì„¤ì •
LOG_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))), 'logs')
os.makedirs(LOG_DIR, exist_ok=True)  # logs í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
LOG_PATH = os.path.join(LOG_DIR, 'langgraph_debug.log')

# ë¡œê±° ì„¤ì •
log = logging.getLogger(__name__)

def format_tool_results(tool_results: List[Any]) -> Dict:
    """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ToolMessage í˜•ì‹ìœ¼ë¡œ ë³€í™˜."""
    
    if not tool_results:
        log.warning("[CallModel:format_tool_results] Empty tool_results")
        return None
        
    # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”
    formatted_output = {
        "stdout": "",
        "artifacts": [],
        "status": "success"
    }

    try:
        # ê²°ê³¼ê°€ ë‹¨ì¼ ê°’ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if not isinstance(tool_results, list):
            tool_results = [tool_results]

        for result in tool_results:
            
            if isinstance(result, dict):
                # ê²°ê³¼ê°€ dictì¸ ê²½ìš° artifactë¡œ ì €ì¥
                formatted_output["artifacts"].append(result)
                if "content" in result:
                    formatted_output["stdout"] += str(result["content"]) + "\n"
            else:
                # ë‹¨ìˆœ ë¬¸ìì—´ì¸ ê²½ìš° stdoutìœ¼ë¡œ ì²˜ë¦¬
                formatted_output["stdout"] += str(result) + "\n"
                
        return formatted_output
            
    except Exception as e:
        log.error(f"[CallModel:format_tool_results] Error formatting tool results: {str(e)}", exc_info=True)
        formatted_output["status"] = "error"
        formatted_output["stdout"] = f"Error formatting tool results: {str(e)}"
        return formatted_output

def call_model(state: Union[Dict, AgentState]) -> Union[Dict, AgentState]:
    """LLMì„ í˜¸ì¶œí•˜ê³  ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ (MCP + ì§ì ‘ êµ¬í˜„ ë„êµ¬ í†µí•©)."""
    try:
        # stateê°€ dictì¸ì§€ AgentStateì¸ì§€ í™•ì¸
        is_dict = isinstance(state, dict)
        
        # ê¸°ë³¸ state êµ¬ì¡° í™•ì¸ ë° ì´ˆê¸°í™”
        if is_dict:
            messages = state["messages"]
            user_location = state.get("user_location")
            summary = state.get("summary")
            user_id = state.get("user_id")
            user_memory = state.get("user_memory", "")
            # ëª¨ë“  ë„êµ¬ ê°€ì ¸ì˜¤ê¸° (MCP + ì§ì ‘ êµ¬í˜„)
            all_tools = []
            if state.get("mcp_tools"):
                all_tools.extend(state["mcp_tools"])
            if state.get("direct_tools"):
                all_tools.extend(state["direct_tools"])
            if not all_tools:
                all_tools = agent_tools  # ê¸°ë³¸ ë„êµ¬
        else:
            messages = state.messages
            user_location = state.user_location
            summary = state.summary
            user_id = state.user_id
            user_memory = state.user_memory or ""
            # ëª¨ë“  ë„êµ¬ ê°€ì ¸ì˜¤ê¸° (MCP + ì§ì ‘ êµ¬í˜„)
            all_tools = state.get_all_tools()
            if not all_tools:
                all_tools = agent_tools  # ê¸°ë³¸ ë„êµ¬

        # ë©”ì‹œì§€ ê²€ì¦
        if not messages:
            log.error("[CallModel] No messages in state")
            if is_dict:
                state["next_step"] = "cleanup"
            else:
                state.next_step = "cleanup"
            return state

        # ë„êµ¬ê°€ ë°”ì¸ë”©ëœ ëª¨ë¸ ì´ˆê¸°í™”
        model = init_langchain_llm(all_tools)
        
        # ë„êµ¬ ëª©ë¡ ë¡œê¹…
        print(f"ğŸ”§ Available tools in call_model: {[tool.name for tool in all_tools]}")
        print(f"ğŸ”§ Total tools count: {len(all_tools)}")
        print(f"ğŸ“¨ Processing message: {messages[-1].content if messages else 'No message'}")

        search_results = []
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì„ì‹œë¡œ ë¹„í™œì„±í™”í•˜ì—¬ ì´ì „ ëŒ€í™” ê°„ì„­ ë°©ì§€
        # if messages and user_id:
        #     from app.services.message_service import MessageService
        #     message_service = MessageService()
        #     latest_message = messages[-1].content if messages else ""
        #     
        #     # í˜„ì¬ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê²€ìƒ‰ë§Œ ìˆ˜í–‰
        #     search_results = message_service.search_similar_messages_pgvector(
        #         user_id=str(user_id),
        #         query=latest_message,
        #         top_k=3
        #     )
        #     
        #     # ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§ - í˜„ì¬ ì§ˆë¬¸ê³¼ ë„ˆë¬´ ë‹¤ë¥¸ ê²°ê³¼ëŠ” ì œì™¸
        #     filtered_results = []
        #     for result in search_results:
        #         # ê²€ìƒ‰ ê²°ê³¼ì˜ ë‚´ìš©ì´ í˜„ì¬ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œì§€ í™•ì¸
        #         if result.get('content') and latest_message:
        #             # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ í•„í„°ë§
        #             current_keywords = set(latest_message.split())
        #             result_keywords = set(result['content'].split())
        #             common_keywords = current_keywords.intersection(result_keywords)
        #             
        #             # ê³µí†µ í‚¤ì›Œë“œê°€ ìˆê±°ë‚˜ í˜„ì¬ ì§ˆë¬¸ì´ ìœ„ì¹˜/êµí†µ ê´€ë ¨ì´ë©´ í¬í•¨
        #             if (len(common_keywords) > 0 or 
        #                 any(keyword in latest_message for keyword in ['ì—­', 'ì§€í•˜ì² ', 'ë²„ìŠ¤', 'ê¸¸', 'ìœ„ì¹˜', 'ì–´ë””', 'ê°€ë‹¤', 'ì˜¤ë‹¤'])):
        #                 filtered_results.append(result)
        #         
        #     search_results = filtered_results
        #     print(f"ğŸ” Search results: {len(search_results)} relevant results found")
        
        print("ğŸ” Search results disabled to prevent interference")

        # ì´ì „ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬
        tool_results = state.get("tool_results") if is_dict else getattr(state, "tool_results", None)
        
        if tool_results:
            tool_output = format_tool_results(tool_results)
            
            if tool_output:
                current_tool_call_id = state.get("current_tool_call_id") if is_dict else getattr(state, "current_tool_call_id", None)
                current_tool_name = state.get("current_tool_name") if is_dict else getattr(state, "current_tool_name", None)
                
                if current_tool_call_id and current_tool_name:
                    tool_message = ToolMessage(
                        content=tool_output["stdout"],
                        tool_call_id=current_tool_call_id,
                        name=current_tool_name
                    )
                    messages.append(tool_message)
                else:
                    log.warning("[CallModel] Missing tool_call_id or tool_name, cannot create ToolMessage")
            else:
                log.warning("[CallModel] Tool output is empty or invalid")
              # ë„êµ¬ ê´€ë ¨ ìƒíƒœ ì´ˆê¸°í™”
            if is_dict:
                state["tool_results"] = None
                state["current_tool_call_id"] = None
                state["current_tool_name"] = None
            else:
                state.clear_tool_state()
            
        current_date = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
        
        # ë„êµ¬ ì‚¬ìš©ì„ ìœ ë„í•˜ëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
        system_message = SystemMessage(content=f"""ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:
{chr(10).join([f"- {tool.name}: {tool.description}" for tool in all_tools])}

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•  ë•Œ í•„ìš”í•œ ë„êµ¬ë¥¼ ì ê·¹ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”:
- ë‚ ì”¨ ì •ë³´ê°€ í•„ìš”í•˜ë©´ weather_daily_forecast ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ìœ„ì¹˜ë‚˜ ì¥ì†Œì— ëŒ€í•œ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ Google Maps ê´€ë ¨ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•˜ë©´ search_web ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ì¼ì • ê´€ë¦¬ê°€ í•„ìš”í•˜ë©´ schedule ê´€ë ¨ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”

**ì¤‘ìš”**: 
- í•­ìƒ ì‚¬ìš©ìì˜ í˜„ì¬ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•˜ì„¸ìš”
- ì´ì „ ëŒ€í™” ê¸°ë¡ì€ ì°¸ê³ ìš©ì´ë¯€ë¡œ, í˜„ì¬ ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ì´ ì—†ìœ¼ë©´ ë¬´ì‹œí•˜ì„¸ìš”
- ê²€ìƒ‰ëœ ì´ì „ ëŒ€í™” ë‚´ìš©ì´ í˜„ì¬ ì§ˆë¬¸ê³¼ ë‹¤ë¥´ë©´ í˜„ì¬ ì§ˆë¬¸ì— ì§‘ì¤‘í•˜ì„¸ìš”

í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ê³ , ë„êµ¬ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” ì •í™•í•œ ì¸ìë¥¼ ì œê³µí•˜ì„¸ìš”.""")

        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ë§¨ ì•ì— ì¶”ê°€
        all_messages = [system_message] + messages
        
        # LLMì— ì „ë‹¬í•  ë©”ì‹œì§€ í¬ë§·íŒ…
        formatted_messages = prompt.format_messages(
            messages=all_messages,
            user_location=user_location or "ìœ„ì¹˜ ì •ë³´ ì—†ìŒ",
            current_date=current_date,
            summary=summary or "ì´ì „ ëŒ€í™” ìš”ì•½ ì—†ìŒ",
            search_results=json.dumps(search_results, ensure_ascii=False) if search_results else "ê´€ë ¨ ëŒ€í™” ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ",
            user_memory=user_memory or "ì¥ê¸°ê¸°ì–µ ì—†ìŒ"
        )
        
        # OpenAI í˜•ì‹ìœ¼ë¡œ ë©”ì‹œì§€ ë³€í™˜
        openai_messages = convert_to_openai_messages(formatted_messages)
        
        try:
            # LangChain ëª¨ë¸ í˜¸ì¶œ
            response = model.invoke(openai_messages)
            
            # tool_calls í™•ì¸ ë° ì²˜ë¦¬
            has_tool_calls = (
                hasattr(response, "additional_kwargs") and 
                "tool_calls" in response.additional_kwargs and
                response.additional_kwargs["tool_calls"]
            )
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            if has_tool_calls:
                tool_calls = response.additional_kwargs["tool_calls"]
                
                if is_dict:
                    state["next_step"] = "tool"
                    # tool ì •ë³´ ì„¤ì •
                    state["current_tool_call_id"] = tool_calls[0]["id"]
                    state["current_tool_name"] = tool_calls[0]["function"]["name"]
                    state["current_tool_args"] = tool_calls[0]["function"]["arguments"]
                else:
                    state.next_step = "tool"
                    # tool ì •ë³´ ì„¤ì •
                    state.set_tool_info(tool_calls)
                print(f"ğŸ”§ Tool call detected: {tool_calls[0]['function']['name']}")
            else:
                # ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´ cleanupìœ¼ë¡œ ì´ë™
                if is_dict:
                    state["next_step"] = "cleanup"
                else:
                    state.next_step = "cleanup"
                print("âœ… No tool calls - moving to cleanup")
            
            # AI ì‘ë‹µì„ messagesì— ì¶”ê°€
            messages.append(response)
            
            if is_dict:
                state["step_count"] = state.get("step_count", 0) + 1
            else:
                state.step_count += 1
                
            print(f"ğŸ¤– AI Response: {response.content}")
            print(f"ğŸ“Š Step count: {state.get('step_count', 0) if is_dict else state.step_count}")
            
            # ë©”ì‹œì§€ ìœ íš¨ì„± ê²€ì‚¬ (AgentStateì¸ ê²½ìš°ì—ë§Œ)
            if not is_dict and not state.validate_messages():
                log.error("[CallModel] Invalid message pattern after adding AI response")
                state.next_step = "cleanup"
                return state
            
        except Exception as e:
            log.error(f"[CallModel] Exception in LLM/tool: {e}", exc_info=True)
            error_msg = AIMessage(content=f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            messages.append(error_msg)
            
            if is_dict:
                state["next_step"] = "cleanup"
            else:
                state.next_step = "cleanup"
            return state
            
    except Exception as e:
        log.error(f"[CallModel] Outer exception:", exc_info=True)
        
        # state íƒ€ì… ë‹¤ì‹œ í™•ì¸
        is_dict = isinstance(state, dict)
        
        if is_dict:
            state["error"] = str(e)
            state["next_step"] = "end"
        else:
            state.error = str(e)
            state.next_step = "end"
            
        return state

    return state 