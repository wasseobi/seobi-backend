"""AI ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì¸ ì‹¤í–‰ íŒŒì¼ì…ë‹ˆë‹¤."""
from dotenv import load_dotenv
load_dotenv()

from datetime import datetime
import uuid
from langchain.schema import HumanMessage, AIMessage

from src import graph
from src.state import ChatState
from src.tools import tools

def create_initial_state(user_input: str) -> dict:
    """ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ì´ˆê¸° ìƒíƒœë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # ìƒíƒœë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ìƒì„±
    return {
        "user_input": user_input,
        "parsed_intent": {},
        "reply": "",
        "action_required": False,
        "executed_result": {},
        "timestamp": datetime.now().isoformat(),
        "user_id": str(uuid.uuid4()),
        "tool_info": None,
        "messages": [
            HumanMessage(content=user_input)
        ]
    }

def print_available_tools():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("\n=== ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤ ===")
    for tool in tools:
        print(f"\nğŸ”§ {tool.name}")
        print(f"   ì„¤ëª…: {tool.description}")
        print(f"   ì˜ˆì‹œ: {get_tool_example(tool.name)}")

def get_tool_example(tool_name: str) -> str:
    """ë„êµ¬ë³„ ì‚¬ìš© ì˜ˆì‹œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    examples = {
        "current_time": "ì§€ê¸ˆ ëª‡ ì‹œì•¼?",
        "google_search": "íŒŒì´ì¬ LangGraphì— ëŒ€í•´ ê²€ìƒ‰í•´ì¤˜",
        "schedule_meeting": "ë‚´ì¼ ì˜¤í›„ 3ì‹œì— íŒ€ ë¯¸íŒ… ì¡ì•„ì¤˜"
    }
    return examples.get(tool_name, "ì˜ˆì‹œ ì—†ìŒ")

# ì„¤ì • ì´ˆê¸°í™”
config = {
    "configurable": {
        "thread_id": "1",
        "model": "google_genai:gemini-pro",
        "temperature": 0.7,
        "max_tokens": 1024
    }
}

if __name__ == "__main__":
    print("ğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ('exit' ë˜ëŠ” 'quit'ìœ¼ë¡œ ì¢…ë£Œ)")
    print_available_tools()
    print("\nëª…ë ¹ì–´:")
    print("- help: ë„ì›€ë§ í‘œì‹œ")
    print("- exit/quit: í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
    print()
    
    # ëŒ€í™” ì„¸ì…˜ ì‹œì‘
    while True:
        user_input = input("\nğŸ¤” ")

        # ì¢…ë£Œ ëª…ë ¹ í™•ì¸
        if user_input.lower() in ["exit", "quit"]:
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ğŸ‘‹")
            break
        
        # ë„ì›€ë§ í‘œì‹œ
        if user_input.lower() == "help":
            print_available_tools()
            continue
        
        # ë¹ˆ ì…ë ¥ ë¬´ì‹œ
        if not user_input.strip():
            continue

        try:
            # ì´ˆê¸° ìƒíƒœ ìƒì„±
            initial_state = create_initial_state(user_input)
            
            # ê·¸ë˜í”„ ì‹¤í–‰
            result = graph.invoke(initial_state, config)
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ í™•ì¸
            if result.get("executed_result", {}).get("error"):
                error = result["executed_result"]["error"]
                print(f"âš ï¸ ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            
        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            print("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        
        print()
